Issue key,Summary,Priority,consequence,rolling upgrade?,"consequence category: 1) whole cluster down, 2) master down, 3) performance degradation, 4) data loss & data corruption, 5) rolling upgrade failure (a cluster with mixed versions fail certain functionality or part of the cluster, but functionality could restore after every node is upgraded), 6) incorrect service result, 7) part of cluster down (clients down, secondary master down), 8) unknown (todo, revisit all system state corruption / unknown)",catastrophic (yes/no)? (We classify a failure to be catastrophic when it prevents all or a majority of the users from their normal access to the system),created after buggy release? (production bug?),"root cause (they can be complicated, we use google doc to explain each case's root cause)","root cause category: 1) data-related bug, including 1.1) data format incompatibility (parsing error), 1.2) data related logic error in full-stop upgrade (not parsing error), 1.3) data related logic error in a mixed cluster (not parsing error, but unexpected interaction between nodes running different versions), 2) data-unrelated bug or logic error in upgrade operation itself, 3) misconfiguration (not failure-inducing configuration change), 4) broken dependency (not upgrading a lib brokes depdency, but upgrading the target system itself breaks dependency)",persistant (P) or runtime (R) data format compatibility?,comments on the consequence & cause of the case,caught in upgrade test case? (yes/no),related to changed constant or on-disk dir structure?,rolling upgrade?,version gap,check upgrade operation caught-after-release,version gap delta,minimum # of nodes / slaves (by guess),buggy version release (earliest release of the affected versions) ,Created,created after buggy release? (production bug?),"does the bug exist on a release version? (x.x.x-alpha, x.x.x-beta, x.x.x-RC1 are not release versions)","how to detect: 1) clear symptom (exception, crash, service stop/irresponsive - all those easy to detect symptoms), 2) data loss/corruption (can be detected by read & compare), 3) gray failure (performance degradation, flaky I/O, some observer considers it failure but others don't - i.e., there's no objective criteria), 4) not clear",comments on detection of this case,detailed reproduction steps (in google docs),is upgrade (or rolling upgrade) + normal read/write/delete enough to trigger the root cause?,"category of reproduction: 1) upgrade (or rolling upgrade), 2) upgrade + any data on old system (data created by trivial write/read in workload generator), 3) special data format (requires special constraint on the operations to generate a corner case data format, e.g., special parameter, a special combination of write/read/delete), 4) special operation (any op other than write/read, not covered by workload generator, including a some operation with a special parameter or config), 5) special configuration (non-default configuration), 6) special timing constraint, 7) not clear how to reproduce","for categories 3 to 6, do unit test or stress test help?","if 1) upgrade and 2) upgrade + any data CANNOT reproduce the failure, can unit tests be combined to reproduce the failure?",comments on reproduction of this case,"how to mitigate? 1) wait for the upgrade to finish on the entire cluster, 2) downgrade, 3) rollback, 4) deploy the fixed new version, 5) manual intervention, 6) perminant damage",comments on mitigation of this case,,is upgrade (or rolling upgrade) + normal read/write/delete enough to trigger the root cause?,is upgrade + stress testing enough to trigger the root cause?,commes on how to trigger,is rolling upgrade + stress testing enough to trigger the root cause?,does it need special operation? (this is same as the left column),what needs to be done to trigger the root cause? (this is split into the rightside 5 columns),does it need read/write/delete with special arguments to trigger the root cause?,does it need special timing constraints to trigger the root cause? ,does it need operations other than read/write/delete and upgrade to trigger the root cause? (write down the number),"if normal read/write/delete is not enough and no timing constraint is required, are the special operations or arguments required covered in existing unit tests?","needs extra stuff to trigger the symptom (even though the root cause is already triggered, e.g., large schema + large cluster to trigger performance slowdowm symptom)?","does it need special config? (including special configuration for entire cluster or multi node,  special configuration for single node)","does a restart or full-stop upgrade mitigate the problem? (e.g., data loss or corruption would need more operations to mitigate than network message unrecognized) (1. restart, 2. patch and restart, 3. manual operations to restore the system state, 4. rollback + abort upgrade)",does downgrade mitigate the problem?,does roll back mitigate the problem?,Can tests be combined to test the special config?,Did the tests exist when the bug was reported?,How many tests need to be combined?
HBASE-6316,Confirm can upgrade to 0.96 from 0.94 by just stopping and restarting,Blocker,new version cluster cannot start,no,1) whole cluster down,yes,no,,1.1) data format incompatibility,P,,,"no (data format error, old data parsed incorrectly by new version)",no,0.94->0.96,,2 minor,1,2013-10-19,03/Jul/12 14:07,no,,1) clear symptom,,,yes,2) upgrade + any data on old system,,,,,,,yes,yes,,,no,normal write,,no,,,,no,no (patch and restart),,,,,
CASSANDRA-1545,NullPointerException on startup after upgrade,Urgent,new version cluster cannot start,no,1) whole cluster down,yes,no,,1.1) data format incompatibility,P,,,changed constant (new constants),no,0.7-beta1->0.7-beta2,,< 1 minor,1,2011-01-10,24/Sep/10 19:33,no,,1) clear symptom,,,yes,2) upgrade + any data on old system (Some specific strategies are required. Stress testing can generate such data.),,,,,,,yes,not sure,,,no,normal write,,no,,,,no,no (patch and restart),,,,,
CASSANDRA-10743,Failed upgradesstables (upgrade from 2.2.2 to 3.0.0),Normal,new version cluster cannot function,no,1) whole cluster down,yes,yes,,1.1) data format incompatibility,P,,,on-disk dir structure,no,2.2.2->3.0.0,,1 major,1,2015-11-09,20/Nov/15 17:16,yes,,1) clear symptom,,,no,3) special data format (a sstable index block finish in the middle of a collection tombstone),not clear,,,,,,yes,no,this involves creating a tricky data format,,no,normal write,,no,,,,no,no (patch and restart),,,,,
CASSANDRA-6733,Upgrade of 1.2.11 to 2.0.5 make IllegalArgumentException in Buffer.limit on read of a super column family,Normal,cannot read super column family data,no,6) incorrect service result,yes (read on super column family all fail),yes,,1.1) data format incompatibility,P,,,looks like changed data format,no,1.2.11->2.0.5,,1 major,1,2014-02-07,19/Feb/14 14:18,yes,,1) clear symptom,,,no,3) special data format (super column family),unit test help,,,,,,yes,yes,"seems yes, not sure if it has to involve 3 versions",,no (create super column family - should be tested),normal write,,no,,,,no,no (patch and restart),,,,,
CASSANDRA-13441,"Schema version changes for each upgraded node in a rolling upgrade, causing migration storms",Normal,migration storm,yes,3) performance degradation,yes,yes,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,"interesting, storm",,looks like updating old tables with new version unnecessarily,yes,"N/A (3.0->3.11, 2.1/2.2->3.0)","yes (old result correct, compared against the new version release time)",N/A,"2 (2 nodes can reproduce the cause, but the symptom may not be as bad)",2015-11-09,12/Apr/17 18:23,yes,,3) gray failure,,,yes,1) upgrade,,,,,,,yes,,"has to involve rolling upgrade, triggers storm",yes,no,normal write to trigger the root cause (sufficiently large cluster with a non-trivial schema to trigger the symptom),,no,,,"yes, needs sufficiently large cluster with a non-trivial schema to trigger the symptom",no,no (patch and restart). Full-stop upgrade should mitigate the problem (assuming all nodes upgrade first before trying to update their schema),,,,,
CASSANDRA-6678,Unwanted schema pull while upgrading nodes from 1.2 to 2.0,Normal,"schema corruption, data corruption",yes,4) data corruption?,no,yes,,1.2) data related logic error in rolling upgrade,R (network),,,changed constant (version number),yes,1.2->2.0,,1 major,2,2013-01-02,07/Feb/14 13:33,yes,,3) gray failure (if no exception got thrown),,,yes,1) upgrade + 6) special timing,,,,,,,yes,"no,  race condition",seems like unexpected interaction,,no,normal write,,yes,,,,no,no (patch and restart). Full-stop upgrade should mitigate the problem (assuming all nodes upgrade first before trying to update their schema),,,,,
CASSANDRA-9116,Indexes lost on upgrading to 2.1.4,Urgent,data loss,no,4) data loss,yes,yes,,1.1) data format incompatibility,P (dir structure),,,on-disk dir structure,no,2.0.12->2.1.4,,1 minor,1,2015-04-01,03/Apr/15 20:57,yes,,2) data loss,,,no,3) special data format (index),unit test help,,,,,,yes,yes,disk structure change,,no,normal write,,no,,,,no,no (patch and restart),,,,,
HDFS-7302,namenode -rollingUpgrade downgrade may finalize a rolling upgrade,Major,incorrectly finalize rolling upgrade (leave system in a wrong state),yes,"8) unknown, system state corruption",yes (upgrade fails),N/A,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,"interesting, downgrade involved",,N/A,yes,N/A,"N/A (old result correct, report did not specify error version)",N/A,2,N/A (cannot find affected version anywhere),28/Oct/14 20:08,N/A,,3) gray failure,,,no,4) special operation (downgrade) + 6) special timing constraint,"yes (they actually has upgrade tests using MiniCluster, they tested downgrade)",,,,,,no,"no, downgrade op",,,yes (rolling upgrade + downgrade),normal write,,yes (need to downgrade while upgrade is in progress),,,,no,yes,,,,,
HDFS-9752,Permanent write failures may happen to slow writers during datanode rolling upgrades,Critical,write failure during rolling upgrade,yes,6) incorrect service result,no,N/A,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,yes,N/A,"N/A (old result correct, report did not specify error version)",N/A,2,N/A (cannot find affected version anywhere),03/Feb/16 22:11,N/A,,1) clear symptom,,,yes,"1) upgrade + 6) special timing (if the client is holding the stream open without writing any data during rolling upgrade, a permanent write failure can occur.",,,,,,,yes,no,need special timing,,no,normal write,,yes (client needs to hold stream open while datanodes in pipeline are being upgraded),,,,no,simply retry the write would help!,,,,,
CASSANDRA-6598,upgradesstables does not upgrade indexes causing startup error.,Normal,"upgrade fails, cluster crash",no,1) whole cluster down,yes,yes,,1.1) data format incompatibility (across 3 versions),P,"interesting, 3 versions, special parameter: don't specify ks/cf",,"no, different file formats",no,1.1.12->1.2.13->2.0,,1 major,1,2013-09-03,16/Jan/14 18:16,yes,,1) clear symptom,,,no (need multiple upgrades),4) special operation (multiple consecutive upgrade),,,,,,,no (need multiple upgrades),,,,yes (consecutive upgrades),consecutive upgrades,,no,,"no, consecutive upgrades",,no,"yes (wait for the first upgrade to fully finish - upgradesstables). no (need to upgrade to patched 1.2, then 2.0)",,,,,
CASSANDRA-8462,Upgrading a 2.0 to 2.1 breaks CFMetaData on 2.0 nodes,Normal,cannot reboot old version nodes during rolling upgrade,yes,7) part of cluster down,no,yes,,1.3) data related logic error in a mixed cluster,R,"interesting, missed because dtest doesn't cover restarting node in a mixed cluster - we would likely miss it too",,changed constant (changed enum),yes,2.0.11->2.1.2,,1 minor,2,2014-11-10,11/Dec/14 18:47,yes,,1) clear symptom,,,no (need to add new node to cluster and then restart old node),"4) special operation (restarting old version node during rolling upgrade, note the restarted node is not restarted with new version)",yes. unit test,,,,,,no (need to add new node to cluster and then restart old node),,,,yes (restart old node + rolling upgrade) yes (add new node and then restart old node),,,no,,,,no,no (patch and restart) yes (full-stop upgrade would mitigate the issue),,,,,
CASSANDRA-6619,Race condition issue during upgrading 1.1 to 1.2,Low,new version node cannot connect to old version nodes during upgrade,yes,5) rolling upgrade failure,yes,yes,,1.3) data related logic error in a mixed cluster,R (involves different version number constant),"interesting, different versions are using different protocols and they still somehow manage to do rolling upgrade, but a data race triggered this failure",,changed constant (changed enum),yes,1.1x->1.2,,1 minor,2,2013-01-02,25/Jan/14 11:20,yes,,"3) gray failure (high read latency, some failed writes, stuck, hang)",,,yes,1) upgrade + 6) special timing (high write/read latency during upgrading,,,,,,,yes,no,race condition,,no,,,"yes, race condition",,,,no,yes,,,,,
YARN-9084,"Service Upgrade: With default readiness check, the status of upgrade is reported to be successful prematurely",Major,upgrade might be shown to be successful incorrectly,no,"8) unknown, system state corruption",no,no,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,no,N/A,"no (old result correct, compared against the new version release time)",N/A,1,2019-02-05,05/Dec/18 20:41,no,,3) gray failure,,,yes,1) upgrade,,,,,,,yes,not sure,"developer's own report, not clear",,no,normal writes,,no,,,,no,no (patch and restart),,,,,
HDFS-6340,DN can't finalize upgrade,Blocker,data nodes cannot finish upgrade,no,1) whole cluster down,yes,yes,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,no,2.2.0->2.4.0,,2 minor,1,2014-04-10,04/May/14 16:25,yes,,3) gray failure,,,yes,1) upgrade,,,,,,,yes,no,seems need a large number of blocks,,no,normal writes,,no,,,,no,no (patch and restart),,,,,
HBASE-10581,ACL znode are left without PBed during upgrading hbase0.94* to hbase0.96+,Critical,master chokes,no,2) master down,yes,yes,,1.2) data related logic error in full-stop upgrade,P,,,"no, format change",no,0.94->0.96+,,2 minor,1,2013-10-19,21/Feb/14 1:01,yes,,1) clear symptom,,,yes,1) upgrade,,,,,,,yes,yes,,,no,normal writes,,no,,,,no,no (patch and restart),,,,,
HBASE-2025,0.20.2 accessed from older client throws UndeclaredThrowableException; frustrates rolling upgrade,Blocker,NPE,yes,5) rolling upgrade failure,yes,no,,1.3) data related logic error in a mixed cluster,R (RPC),"interesting, it's a bug in HBase's own implemented RPC lib, it's caused by temporary data over the network",,changed constant,yes,0.20.0->0.20.2,,< 1 minor,2,2010-05-18,02/Dec/09 21:11,no,,1) clear symptom,,,yes,1) upgrade,,,,,,,yes,,simple broken protobuf,yes,no,normal writes,,no,,,,no,yes,,,,,
HDFS-6601,Issues in finalizing rolling upgrade when there is a layout version change,Blocker,"can't finish rolling upgrade, name node terminate",yes,2) master down,yes,no,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,yes,N/A,"no (old result correct, compared against the new version release time)",N/A,1,2015-11-19,24/Jun/14 20:19,no,,1) clear symptom,,,yes,1) upgrade,,,,,,,yes,,it requires rolling upgrade + layout version change,may be,,N/A,,no,,,,no,no (patch and restart),,,,,
HDFS-1936,Updating the layout version from HDFS-1822 causes upgrade problems.,Blocker,corrupt hdfs,no,1) whole cluster down,yes,no,,1.1) data format incompatibility,P,,,changed constant,no,0.20 -> 0.22 -> 0.23,,1 minor,1,2011-12-11,13/May/11 16:51,no,,1) clear symptom,,,yes,1) upgrade,,,,,,,yes,yes,,,,normal write,,no,,,,no,no (patch and restart),,,,,
CASSANDRA-4195,error in log when upgrading multi-node cluster to 1.1,Normal,old node cannot join the ring,yes,5) rolling upgrade failure,"yes, can't serve read/write in a mixed cluster",yes,,1.1) data format incompatibility,R,"interesting, developer said ""how did we miss this in testing?"", solution is tricky",,"no, format change, schema version number change",yes,1.0.9->1.1.0,,1 minor,2,2012-04-24,30/Apr/12 14:17,yes,,1) clear symptom,,,yes,1) upgrade,,,,,,,yes,,simple UUID parsing error,yes,,nothing,,no,,,,no,no (patch and restart),,,,,
CASSANDRA-11315,Fix upgrading sparse tables that are incorrectly marked as dense,Normal,cassandra cannot start,no,1) whole cluster down,yes,yes,,1.1) data format incompatibility,P,,,no,no,2.2.5->3.0.3 or 2.2.6->3.0.5,,1 major,1,2016-02-09,08/Mar/16 11:46,yes,,1) clear symptom,,,yes,3) special data format (create a table with is_dense flag set to true),yes. unit test has is_dense,,,,,,yes,"not sure, may be no","needs to create ""dense"" table",,,create a dense table,,no,,,,no,no (patch and restart),,,,,
ZOOKEEPER-1805,"""Don't care"" value in ZooKeeper election breaks rolling upgrades",Blocker,stops upgrade,yes,5) rolling upgrade failure,yes,no,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,yes,N/A,"no (old result correct, compared against the new version release time)",N/A,3,"2014-03-12 (not clearly stated, maybe rolling upgrade from 3.4.5 to trunk at that time)",30/Oct/13 3:18,no,,1) clear symptom,,,no (special timing),6) special timing (but simple rolling upgrade could trigger it from time to time),,,,,,,no (special timing),,,,,normal leader election,,yes,,,,no,no (patch and restart),,,,,
KAFKA-7403,Offset commit failure after upgrading brokers past KIP-211/KAFKA-4682,Blocker,clients with older version fail,yes (client vs server),7) part of cluster down,yes,yes,,1.3) data related logic error in a mixed cluster,R,"interesting, complicated interaction",,"no, format change plus config change",yes (client vs server),0.11->2.0,,2 major,2,2018-07-28,11/Sep/18 23:52,yes,,1) clear symptom,,,yes,"5) special coniguration (inter.broker.protocol.version was set to ""1.0"" prior to the upgrade",,,,,,,yes,"yes, may be",as long as the request is sent by normal operations,,,nothing,,no,,,,no,yes,,,,,
YARN-9056,Yarn Service Upgrade: Instance state changes from UPGRADING to READY without performing a readiness check,Critical,not clear,no,"8) unknown, system state corruption",no,no,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,no,no,N/A,"no (old result correct, compared against the new version release time)",N/A,1,2019-02-05,26/Nov/18 22:33,no,,3) gray failure,,,yes,1) upgrade,,,,,,,yes,yes,but very hard to detect,,,N/A,,no,,,,no,not clear no,,,,,
YARN-8346,"Upgrading to 3.1 kills running containers with error ""Opportunistic container queue is full""",Blocker,all old containers killed,not sure,3) performance degradation,yes,yes,,1.2) data related logic error in full-stop upgrade,P (work preserving NM restart),"interesting, complicated scenario",,"no, new constant with no default value for upgraded containers",not sure,2.8.4->3.1,,1 major,1,2018-04-05,23/May/18 12:30,yes,,3) gray failure,,,yes,1) upgrade,,,,,,,yes,,requires distributed cache to be enabled,not sure,,normal job,,no,,,,no,no (patch and restart),,,,,
MAPREDUCE-5939,StartTime showing up as the epoch time in JHS UI after upgrade,Major,wrong web UI message,"yes, not sure",6) incorrect service result,no,no,,1.1) data format incompatibility,P,,,on-disk dir structure (new job history file includes timestamp),"yes, not sure",0.23.x->2.5,,2 major,1,2015-11-09,23/Jun/14 20:13,no,,3) gray failure,,,yes,1) upgrade,,,,,,,yes,yes,simple data format reverse,,,normal job,,no,,,,no,no (patch and restart),,,,,
CASSANDRA-6732,Cross DC writes not compatible 1.2->1.1 during rolling upgrade,Normal,cross data center writes lost,yes,4) data loss,yes,yes,,1.3) data related logic error in a mixed cluster,R,"interesting, complicated interaction",,changed constant (constant replaced by two new constants),yes,1.1.x->1.2.x,,1 minor,2,2014-02-07,19/Feb/14 13:17,yes,,3) gray failure,,,yes,5) special configuration (multiple data center),yes. unit test covers multiple dc,,,,,,yes,yes,,,,normal job (across data center),,no,,,,yes (multi data center),no (manual operations needed),,,"no (EC2SnitchTest + any workload + upgrade_through_versions_test.py, but not sure how to test packet loss)",N/A,N/A
HDFS-6981,Fix DN upgrade with layout version change,Major,data loss,yes,4) data loss,no,no,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,no,yes,?->2.6.0,,1 minor,1,2014-11-30,01/Sep/14 21:40,no,,2) data loss,,,no,3) special data format (created by a special complicated combination of normal read/write) + 4)special operation (rollback?),"no, don't think this complicated scenario is covered in test",,,,,,no,,,,,a combinartion of special operations,,no,,,,no,no (manual restore lost data),,,,,
KAFKA-6238,Issues with protocol version when applying a rolling upgrade to 1.0.0,Major,service cannot start,yes,1) whole cluster down,yes,yes,,3) misconfiguration,configuration,,,"no, configuration",yes,0.10.0.1 -> 1.0.0,,1 major,1,2017-10-31,20/Nov/17 11:05,yes,,1) clear symptom,,,yes,5) special config (old config from old version),yes. test case,,,,,,yes,"yes, but special config",,,,normal start,,,,,,old config,no (patch and restart),,,yes (upgrade_test.py),yes,1
CASSANDRA-5696,Upgrading to cassandra-1.2 with a dead LEFT state from 1.1 causes problems,Normal,"old nodes fail best case: harmless exceptions, worst case: a node whose token somehow matches a timestamp will need to be restarted and rebootstrapped. some previously working nodes need to be restarted",yes,"8) unknown, system state corruption",no,yes,,1.1) data format incompatibility,R,,,no,yes,1.1->1.2,,1 minor,2,2013-01-02,24/Jun/13 21:34,yes,,1) clear symptom,,,"no (need to have decomissioned nodes first, then perform a rolling upgrade)",1) upgrade (rolling upgrade),,,,,,,"no (need to have decomissioned nodes first, then perform a rolling upgrade)",,,,,no job,,no,1 (decommision a node),,,no,yes,,,,,
CASSANDRA-12423,Cells missing from compact storage table after upgrading from 2.1.9 to 3.7,Normal,data cannot be retrived (not sure if there's data loss),no,4) data loss,no,yes,,1.1) data format incompatibility,P,,,no,no,2.1.9->3.0+,,1 major,1,2015-11-09,10/Aug/16 8:27,yes,,2) data loss,,,no (delete needs to be performed with EOC parameter = 0),3) special data format (created by combination of nomal operations),"no, how to set EOC=0 is hard",,,,,,no (delete needs to be performed with EOC parameter = 0),,,,,create and special delete,,no,,,,no,no (patch and restart),,,,,
HBASE-9973,[ACL]: Users with 'Admin' ACL permission will lose permissions after upgrade to 0.96.x from 0.94.x or 0.92.x,Major,admin users lost permission,no,4) data loss,yes (indirectly influence users),yes,,1.1) data format incompatibility,P,,,no,no,0.94->0.96,,2 minor,1,2013-10-19,14/Nov/13 19:09,yes,,"1) clear symptom (admin loses permission, has to use admin to trigger)","no data loss, but some data was forgot to be migrated",,yes,1) upgrade,,,,,,,yes,"may be, not sure, need to create admin user on hbase",,,,"maybe not, depends on whether hbase admin needs to be created by hand",,no,,,,no,no (manually restore the admin's acl required),,,,,
HDFS-11856,Ability to re-add Upgrading Nodes (remote) to pipeline for future pipeline updates,Major,upgraded nodes will be excluded from some streams,yes,6) incorrect service result,no,yes,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,no,yes,N/A,"yes (old result correct, compared against the new version release time)",N/A,2,2016-08-25,19/May/17 12:13,yes,,3) gray failure,,,yes,1) upgrade + 6) special timing,,,,,,,yes,,"rolling upgrade and write needs to happen together, timing",no,,normal write,,no,,,,no,yes (maybe),,,,,
CASSANDRA-13320,upgradesstables fails after upgrading from 2.1.x to 3.0.11,Normal,upgrade sstable op fails,no,1) whole cluster down,yes,yes,,1.1) data format incompatibility,P,,,no,no,2.1.16 -> 3.0.11,,1 major,1,2017-02-21,10/Mar/17 8:08,yes,,1) clear symptom,,,yes,3) special operation (tombstone required),yes. unit test,,,,,,yes,yes,as long as delete is normal op,,,normal writes,,no,,,,no,no (patch and restart),,,,,
HDFS-7575,Upgrade should generate a unique storage ID for each volume,Critical,balancer malfunctions,no / not sure,3) performance degradation,no,yes,,1.3) data related logic error in a mixed cluster,P,"interesting, this is a complicated case",,"no, but it's in VERSION file which contains meta data for HDFS",no / not sure,2.0.0- ->2.3.0,,3 minor,2,2014-02-24,30/Dec/14 12:15,yes,,3) gray failure,,,yes,1) upgrade,,,,,,,yes,yes,very hard to detect though,,,normal writes,,no,,,,no,no (manually change the disk files),,,,,
YARN-6585,RM fails to start when upgrading from 2.7 to 2.8 for clusters with node labels.,Blocker,ResourceManager fails to start,no,2) master down,yes,yes,,1.1) data format incompatibility,P,,,changed constant (changed field name),no,2.7->2.8,,1 minor,1,2017-03-24,11/May/17 18:18,yes,,1) clear symptom,,,yes (need labeled nodes),3) special data format (add node labels) (Can label be generated by normal operation?),yes. unit test covers node label,,,,,,yes (need labeled nodes),not sure,it needs labled nodes; this case developers also mentioned compatibility divergence!,,,normal writes,,no,,,,no,no (patch and restart),,,,,
CASSANDRA-3849,Saved CF row cache breaks when upgrading to 1.1,Normal,upgraded nodes fail to start,not clear / no,1) whole cluster down,yes,no,,1.2) data related logic error in full-stop upgrade,P,"persistent cache data can be parsed, but there's a check that fails if that cache data exists from old version",,no,not clear / no,1.0->1.1,,1 minor,1,2012-04-24,04/Feb/12 2:03,no,,1) clear symptom,,,yes (need to have cached data),"3) special data format (force saving the cache data, which is usually not saved)",yes. unit test covers cache,,,,,,yes (need to have cached data),not sure,needs to enable row and key caching,,,normal writes (but needs to trigger cache save),,no,,,,"yes (not sure these setup are special: key cache and column cache enabled, cache size small so that cache is saved on disk)",no (patch and restart),,,yes (global_row_key_cache_test.py + upgrade_test.py),yes,2
HDFS-3731,2.0 release upgrade must handle blocks being written from 1.0,Blocker,Data loss in the upgraded system,no,4) data loss,yes,yes,,1.1) data format incompatibility,P (forgot about bbw files when upgrade),,,"no (it forgot to load some disk files during upgrade, but those files exist in both versions)",no,"0.21+, 1.x->2.0",,1 major,1,2012-05-23,26/Jul/12 15:24,yes,,2) data loss,,,no (need to have bbw files on disk),3) special data format (BBW blocks created by unfinished writes),"not sure if we could create BBW blocks, crash hdfs before a write finishes? ",,,,,,no (need to have bbw files on disk),,,,,normal writes,,yes (need to stop old cluster while some blocks are not finished writing to create bbw files on disk),,,,no,no (manually restore lost data),,,,,
CASSANDRA-12249,dtest failure in upgrade_tests.paging_test.TestPagingDataNodes3RF3_Upgrade_current_3_0_x_To_indev_3_x.basic_paging_test,Normal,node fails,yes,6) incorrect service result,no (only for paging request),no,,1.3) data related logic error in a mixed cluster,R,this interaction is quite simple. the root cause is an incorrectly handled constant. although it manifested as a parsing error. ,,changed constant,yes,3.08->3.8,,> 3 minor,2,2016-09-29,20/Jul/16 15:47,no,,1) clear symptom,,,yes,4) special operation (paging query),"yes. There are tests related to paging query in the unit test, but it must be executed during the rolling upgrade",,,,,,yes,,,"seems yes, needs to do paging",,normal writes,,no,,,,no,no (patch and restart),,,,,
CASSANDRA-14820,Upgrade to 4.0 fails with NullPointerException,Normal,service down,no,1) whole cluster down,yes,no,,1.1) data format incompatibility,P,,,changed constant (new constant),no,"3.0.x, 3.11.x->4",,1 major,1,not released yet,12/Oct/18 11:07,no,,1) clear symptom,,,yes,1) upgrade,,,,,,,yes,"yes, may be, requires additional write",,,,normal writes,,no,,,,no,no (patch and restart),,,,,
HBASE-10582,0.94->0.96 Upgrade: ACL can't be repopulated when ACL table contains row for table '-ROOT' or '.META.',Critical,ACL zookeeper nodes cannot join zookeeper,no,4) data loss,yes (all permissions lost),yes,,1.1) data format incompatibility,P,,,no,no,0.94->0.96,,2 minor,1,2013-10-19,21/Feb/14 1:09,yes,,1) clear symptom,,,no (need ACLs on system tables),3) special data format (write ACLs on system tables),"yes. operations are normal, but no test write ACLs on system tables. might be possible if we combine operations from different unit tests. even if it's triggered, it could not be detected",,,,,,no (need ACLs on system tables),,,,,operation with special arguments (create acl entry for root and meta),,no,,,,no,no (patch and restart),,,,,
HDFS-6198,DataNode rolling upgrade does not correctly identify current block pool directory and replace with trash on Windows.,Major,Data node fails,yes,1) whole cluster down,yes,no,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,yes,N/A,old result correct,N/A,1,2014-04-10,07/Apr/14 20:30,no,,1) clear symptom,,,no,5) special configuration (on Windows),,,,,,,yes,,,"no, need windows environment",,normal rolling upgrade,,no,,,,windows,no (patch and restart),,,yes (TestDataNodeRollingUpgrade),yes,1
HDFS-11448,JN log segment syncing should support HA upgrade,Major,upgrade fails rollback fails on winows (due to directory in use),no,6) incorrect service result,no (only JN log download fails),no,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,no,N/A,old result correct,N/A,2 (2 journal nodes),2017-07-07,23/Feb/17 19:55,no,,1) clear symptom,,,no (need rollback during JN download),"4) special operation (crash JN, trigger JN sync, combine with downgrade) + 6) special timing constraint",yes. downgrade is not tested with JN sync. Combining unit tests might help. ,,,,,,no (need rollback during JN download),,,,,roll back,,yes (need rollback during JN download),,,,windows,no (patch and restart),,,yes (testJournalNodeSync + testRollbackWithHAQJM),yes,2
CASSANDRA-13119,dtest failure upgrade_tests.upgrade_supercolumns_test.TestSCUpgrade.upgrade_super_columns_through_all_versions_test,Urgent,"data loss, system table cannot be upgraded",no,4) data loss,yes (system tables lost),yes,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,no,N/A,,N/A,1,2016-05-13,11/Jan/17 21:57,yes,,2) data loss,,,yes,"1) upgrade (System table error, but not sure whether super CF is necessary.)",,,,,,,yes,yes,meta/system tables not upgraded,,,normal writes,,no,,,,no,no (patch and restart),,,,,
KAFKA-1107,Broker unnecessarily recovers all logs when upgrading from 0.8 to 0.8.1,Blocker,wasted computation,no,3) performance degradation,no,no,,1.2) data related logic error in full-stop upgrade  (more like optimization),P,,,on-disk dir structure,no,0.8->0.8.1,,< 1 minor,1,2014-2-21,29/Oct/13 18:16,no,,3) gray failure,,,yes,1) upgrade,,,,,,,yes,yes,but hard to detect,,,normal writes,,no,,,,no,no (patch and restart),,,,,
KAFKA-6054,"ERROR ""SubscriptionInfo - unable to decode subscription data: version=2"" when upgrading from 0.10.0.0 to 0.10.2.1",Major,nodes with old version fail,yes,5) rolling upgrade failure,yes,yes,,1.1) data format incompatibility,R,,,changed constant,yes,0.10.0.0->0.10.2.1,,< 1 minor,2,2017-04-26,11/Oct/17 16:40,yes,,1) clear symptom,,,yes,1) rolling upgrade,,,,,,,yes,yes,may be,,,normal writes,,no,,,,no,yes,,,,,
YARN-2819,NPE in ATS Timeline Domains when upgrading from 2.4 to 2.6,Critical,can't load old data,no,6) incorrect service result,no (only timeline service down),no,,1.1) data format incompatibility,P,,,changed constant (new field),no,before2.6.0->2.6.0,,1 minor,1,2014-11-30,06/Nov/14 18:27,no,,1) clear symptom,,,no (need to test timeline server),2) upgrade + any data,,,,,,,no (need to test timeline server),,,,,normal writes,,no,,,,no,no (patch and restart),,,,,
HBASE-3499,Users upgrading to 0.90.0 need to have their .META. table updated with the right MEMSTORE_SIZE,Blocker,slow down the entire cluster,no,3) performance degradation,yes,yes,,3) misconfiguration,N/A,,,N/A,no,0.20->0.90,,> 3 minor,1,2011-01-30,02/Feb/11 19:40,yes,,3) gray failure,,,no (need .META to be set to be small in the first place),5) special configuration (very small .META table),no such small config in unit tests,,,,,,no (need .META to be set to be small in the first place),,,,,normal writes,,no,,,,config,no (apply script during upgrade),,,"no (doesn't seem to be any test which sets the memstoreflushsize smaller than the default, and doesn't seem to be any test which tests startup performance)",,
CASSANDRA-6702,Upgrading node uses the wrong port in gossiping,Low,performance slow down,yes,3) performance degradation,no,yes,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,yes,"1.1.7->1.2.13, 1.2.15",,1 minor,2,2013-12-19,13/Feb/14 23:17,yes,,3) gray failure,,,no (need multiple regions too),5) special configuration (multiple regions and Ec2MultiRegionSnitch),yes. EC2SnitchTest,,,,,,no (need multiple regions too),,,,,normal writes,,no,,,,"yes, has to use Ec2MultiRegionSnitch",no (patch and restart) yes,,,"no (EC2SnitchTest + any workload + upgrade_through_versions_test.py, but not sure how to test cycle of reconnection)",N/A,N/A
HDFS-3597,SNN can fail to start on upgrade,Minor,second name node fails to start,no,7) part of cluster down,no (secondary master down),yes,,1.1) data format incompatibility,P,,,changed constant,no,1.x->2.0.0-alpha,,1 major,2,2012-05-23,04/Jul/12 0:13,yes,,1) clear symptom,,,yes,1) upgrade,,,,,,,yes,yes,meta data,,,normal writes,,no,,,,no,no (patch and restart),,,,,
CASSANDRA-11763,Failure to read non-shallow pre-3.0 sstable index entries,Normal,cassandra cannot start,no,1) whole cluster down,yes,no,,1.1) data format incompatibility,P,"interesting, there's correct parsing logic, it's just that they accidentally used the wrong logic",yes,no,no,2.x->3.6+,,1 major,1,N/A,12/May/16 14:51,no,,1) clear symptom,,,yes,3) special data format (not exactly sure how to generate non-shallow sstables),not sure,,,,,,yes,,,"no, run rolling upgrade with non-shallow tables",,normal writes,,no,,,,no,no (patch and restart),,,,,
CASSANDRA-4843,When upgrading from 1.1.6 to 1.20 change in partitioner causes nodes not to start,Normal,cassandra cannot start,no,1) whole cluster down,yes,no,,3) misconfiguration,configuration,,,"no, config constant",no,1.1.6->1.2.0,,2 minor,1,2013-01-02,21/Oct/12 14:15,no,,1) clear symptom,,,yes,1) upgrade,"configuration is default, the problem is that the default configuration changed and is incompatible between old and new version",,,,,,yes,yes,miconfiguration,,,normal writes,,no,,,,yes(config),no (patch and restart),,,upgrade_through_versions_test.py,yes,1
CASSANDRA-5660,Gossiper incorrectly drops AppState for an upgrading node,Low,"upgraded nodes cannot communicate with old nodes, infinite loop",yes,5) rolling upgrade failure,yes,yes,,1.3) data related logic error in a mixed cluster,R,,,version constant,yes,1.1.x->1.2.x,,1 minor,2,2013-01-02,19/Jun/13 13:07,yes,,1) clear symptom,,,no (need multiple regions too),5) special configuration (multiple regions and Ec2MultiRegionSnitch),yes. EC2SnitchTest,,,,,,no (need multiple regions too),,,,,normal rolling upgrade,,no,,,,yes (Ec2MultiRegionSnitch config),no (patch and restart),,,"no (EC2SnitchTest + upgrade_through_versions_test.py, but not sure how to test constant reconnection)",N/A,N/A
MESOS-3834,slave upgrade framework checkpoint incompatibility,Major,new version node cannot start,no,1) whole cluster down,yes,yes,,1.1) data format incompatibility,P,,,no (missing data not handled correctly ),no,0.22->0.24.1,,2 minor,1,2015-09-18,05/Nov/15 4:35,yes,,1) clear symptom,,,yes,1) upgrade,,,,,,,yes,yes,,,,,,no,,,,no,,,,,,
MESOS-5031,Authorization Action enum does not support upgrades.,Major,agent cannot register,yes / ?,5) rolling upgrade failure,yes,N/A (but it's found because of another upgrade bug found after release),,1.1) data format incompatibility,R,Note: these 4 cases are the same!,,changed constant,yes / ?,N/A,,N/A,2,N/A,25/Mar/16 7:57,N/A (but it's found because of another upgrade bug found after release),,1) clear symptom,,,yes,4) special operation (authorization action?),yes. unit test,,,,,,yes,yes,,,,,,no,,,,no,,,,,,
MESOS-5018,FrameworkInfo Capability enum does not support upgrades.,Major,agent cannot register,yes / ?,5) rolling upgrade failure,yes,N/A (but it's found because of another upgrade bug found after release),,1.1) data format incompatibility,R,Note: these 4 cases are the same!,,changed constant,yes / ?,N/A,,N/A,2,N/A,23/Mar/16 23:22,N/A (but it's found because of another upgrade bug found after release),,1) clear symptom,,,yes,4) special operation (authorization action?),yes. unit test,,,,,,yes,yes,,,,,,no,,,,no,,,,,,
MESOS-2371,Removing internal namespace for protobufs results in incompatible upgrade,Blocker,,yes,5) rolling upgrade failure,yes,no,,1.1) data format incompatibility,R,Note: these 4 cases are the same!,,changed constant,yes,0.21.0->0.22.0,,1 minor,2,2015-03-24,18/Feb/15 20:25,no,,1) clear symptom,,,yes,1) upgrade,,,,,,,yes,,,yes,,,,no,,,,no,,,,,,
MESOS-7828,Current approach to parse protobuf enum from JSON does not support upgrades,Major,agent cannot register,no / not sure,5) rolling upgrade failure,yes,N/A (but it's found because of another upgrade bug found after release),,1.1) data format incompatibility,R,Note: these 4 cases are the same!,,changed constant,no / not sure,N/A,,N/A,2,N/A,25/Jul/17 14:58,N/A (but it's found because of another upgrade bug found after release),,1) clear symptom,,,yes,1) upgrade,,,,,,,yes,yes,,,,,,no,,,,no,,,,,,
MESOS-8341,Agent can become stuck in (re-)registering state during upgrades,Major,agent cannot register,yes / ?,7) part of cluster down,no,N/A (perhaps not),,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,yes / ?,N/A,,N/A,2,N/A,18/Dec/17 11:26,N/A (perhaps not),,"1) clear symptom (""registration are discarded"")",,,"yes (old version < minimum supported version, then rolling upgrade)",1) upgrade (rolling upgrade),,,,,,,"yes (old version < minimum supported version, then rolling upgrade)",not sure,a lot of conditions for it to be triggered,,,,,no,,,,no,,,,,,
MESOS-7316,Upgrading Mesos to 1.2.0 results in some information missing from the `/flags` endpoint.,Critical,data loss,no,4) data loss,no,yes,,1.2) data related logic error in full-stop upgrade,P,"the data was fine, but the parsing logic cannot be accessed in the new version because of the changed code",,no,no,1.1.0->1.2.0,,1 minor,1,2017-3-8,27/Mar/17 20:39,yes,,2) data loss,,,yes,1) upgrade,,,,,,,yes,yes,,,,,,no,,,,no,,,,,,
HDFS-6135,"In HDFS upgrade with HA setup, JournalNode cannot handle layout version bump when rolling back",Blocker,journal node cannot handle new version,no,6) incorrect service result,no (journal node fails),N/A,,1.3) data related logic error in a mixed cluster,P,"interesting, error in rollback logic",,changed constant,no,N/A,,N/A,1,N/A,21/Mar/14 6:10,N/A,,1) clear symptom,,,yes,4) special operation (downgrade JN),"yes, unit test",,,,,,yes,"no, needs roll back",,,,,,no,,,,no,,,,,,
HDFS-6197,Rolling upgrade rollback on Windows can fail attempting to rename edit log segment files to a destination that already exists.,Minor,cannot discard edit log,yes,6) incorrect service result,no (roll back fails),no,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,error in rollback,yes,N/A,yes,N/A,,N/A,2,2014-04-10,07/Apr/14 17:52,no,,1) clear symptom,,,no (need rollback),4) special operation (downgrade) + 5) special configuration (Windows),Windows is not explicitly configured in unit tests. But it's expected to test on Windows. ,,,,,,no (need rollback),,,,,,,no,,,,no,,,,yes (existing test triggered it),,
HDFS-6569,OOB message can't be sent to the client when DataNode shuts down for upgrade,Major,client write failure,yes,6) incorrect service result,no,yes,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,yes,N/A,,N/A,1,2014-04-10,19/Jun/14 18:31,yes,,1) clear symptom,,,"no (long write + upgrade, timing)",6) special timing constraint,,,,,,,"no (long write + upgrade, timing)",,,,,,,yes,,,,no,,,,,,
HDFS-7443,Datanode upgrade to BLOCKID_BASED_LAYOUT fails if duplicate block files are present in the same volume,Blocker,cluster down,no,7) part of cluster down,no,no,,1.1) data format incompatibility,P,,,no (duplicated block file),no,2.5->2.6,,1 minor,1,2014-11-30,25/Nov/14 14:17,no,,1) clear symptom,,,not sure (how to create duplicate blocks in old version?),3) special data format (duplicated blocks),not sure,,,,,,not sure (how to create duplicate blocks in old version?),,,,,,,not sure,,,,no,,,,,,
HDFS-9500,datanodesSoftwareVersions map may counting wrong when rolling upgrade,Major,,yes,6) incorrect service result,no,yes,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,yes,2.6.0->2.6.2,,< 1 minor,2,2015-10-28,03/Dec/15 6:17,yes,,3) gray failure,,,"no ? (timing, right?)",1) upgrade (rolling upgrade) + 6) special timing constraint,,,,,,,"no ? (timing, right?)",,,,,,,yes ?,,,,no,,,,,,
HDFS-5138,Support HDFS upgrade in HA,Blocker,this is a missing feature,no,1) whole cluster down,yes,no,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,no,2.0.x->2.1.x,,1 minor,1,Sep 17 05:46:41 2013,27/Aug/13 22:44,no,,1) clear symptom,,,no,1) upgrade (rollling upgrade),,,,,,,no,,,,,,,no,,,,no,,,,,,
HDFS-7042,Upgrade fails for Windows HA cluster due to file locks held during rename in JournalNode.,Blocker,upgrade fails (is it that all upgrade fail cases can be categorized as whole cluster down? do they do automated roll back?),no,1) whole cluster down,yes,yes,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,no,N/A,,N/A,1,Jun 30 07:04:57 2014,10/Sep/14 22:52,yes,,1) clear symptom,,,no,5) special configuration (Windows),Windows is not explicitly configured in unit tests. But it's expected to test on Windows. ,,,,,,no,,,,,,,no,,,,windows,,,,yes (existing test on windows triggers it),,
HDFS-7929,inotify unable fetch pre-upgrade edit log segments once upgrade starts,Major,data loss,no,4) data loss,yes,N/A,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,no,N/A,,N/A,1,N/A,13/Mar/15 17:20,N/A,,2) data loss,,,yes,2) upgrade + stress testing,,,,,,,yes,"no, it relies on inotify - an outside utill to trigger",,,,,,no,,,,no,,,,,,
HDFS-5988,Bad fsimage always generated after upgrade (interesting),Blocker,data loss,no,4) data loss,yes,no,,1.1) data format incompatibility,P,,"no, but caught in internal test",no ? (maybe layout version constant?),no,N/A,,N/A,1,Apr 10 12:31:11 2014,20/Feb/14 23:00,no,,1) clear symptom,,,yes,2) upgrade + stress testing,,,,,,,yes,yes,,,,,,no,,,,no,,,,,,
HDFS-7185,The active NameNode will not accept an fsimage sent from the standby during rolling upgrade,Major,"cannot transfer fsimage to NN, upgrade success",yes,6) incorrect service result,no,yes,,1.3) data related logic error in a mixed cluster,R (fsimage sent over network),,,changed constant (version number?),yes,N/A,,N/A,2,Apr 10 12:31:11 2014,03/Oct/14 1:31,yes,,1) clear symptom,,,"no (checkpoint, timing)",1) rolling upgrade,,,,,,,"no (checkpoint, timing)",,,,,,,"yes ? (2NN checkpoint, send fsimage to NN before finalize)",,,,no,,,,,,
HDFS-7932,Speed up the shutdown of datanode during rolling upgrade,Major,,yes,3) performance degradation,no,N/A,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,yes,N/A,,N/A,1,N/A,13/Mar/15 21:43,N/A,,3) gray failure,,,yes,2) upgrade (rolling upgrade) + stress testing (busy IO),,,,,,,yes,no,needs busy IO,,,,,yes ? (rolling upgrade during write?),,,,no,,,,,,
HDFS-8676,Delayed rolling upgrade finalization can cause heartbeat expiration and write failures,Critical,lose hundreds of nodes,yes,7) part of cluster down,yes,N/A,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,yes,N/A,,N/A,1,N/A,26/Jun/15 16:32,N/A,,3) gray failure,,,no (large amount of writes),3) special data format (large data generated by huge amount of writes) + 6) special timing (generate large amount of data before finalize upgrade),no. stress testing might help if we use it to an extreme,,,,,,no (large amount of writes),,,,,,,no,,,,no,,,,,,
HDFS-7131,"During HA upgrade, JournalNode should create a new committedTxnId file in the current directory",Major,master down,no,2) master down,yes,yes,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,no,N/A,,N/A,1,Apr 10 12:31:11 2014,23/Sep/14 1:36,yes,,1) clear symptom,,,no (roll back),4) special operation (downgrade),yes,,,,,,no (roll back),,,,,,,no,,,,no,,,,,,
HDFS-8127,NameNode Failover during HA upgrade can cause DataNode to finalize upgrade,Blocker,cannot roll back,yes,"8) unknown, system state corruption",no,yes,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,yes,N/A,,N/A,2,Apr 10 12:31:11 2014,10/Apr/15 17:27,yes,,1) clear symptom,,,"no (fail over, roll back)",4) special operation (downgrade),yes,,,,,,"no (fail over, roll back)",,,,,,,no,,,,no,,,,,,
HBASE-16752,Upgrading from 1.2 to 1.3 can lead to replication failures due to difference in RPC size limit,Major,fail to replicate data,yes,6) incorrect service result,no,no,,1.1) data format incompatibility,R,,,changed constant (new constant),yes,1.2->1.3,,1 minor,2,2017-02-10,03/Oct/16 19:56,no,,1) clear symptom,,,no (large write),3) special data format (send an RPC with > 256 MB data),no. stress testing might help if we use it to an extreme,,,,,,no (large write),,,,,,,no,,,,no,,,,,,
HBASE-18132,Low replication should be checked in period in case of datanode rolling upgrade,Major,data corruption,yes,6) incorrect service result (WAL file cannot be opened),no,yes,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,yes,N/A,,N/A,2,2017-04-26,30/May/17 12:27,yes,,1) clear symptom,,,"yes (but, you need to read the WAL file)",3) special data format (need WAL with little writes),not sure,,,,,,"yes (but, you need to read the WAL file)","not sure, ",it requires a special type of WAL log file to be generated,,,,,no,,,,no,,,,,,
HDFS-11209,SNN can't checkpoint when rolling upgrade is not finalized (duplicate 7185),Critical,"cannot transfer fsimage to NN, upgrade success",yes,6) incorrect service result,no,no,,1.3) data related logic error in a mixed cluster,R (fail to push checkpoint over network),,,changed constant (version number?),yes,N/A,,N/A,2,Mar 24 13:17:29 2017,06/Dec/16 0:02,no,,1) clear symptom,,,"no (checkpoint, timing)",6) special timing constraint,,,,,,,"no (checkpoint, timing)",,,,,,,"yes ? (2NN checkpoint, send fsimage to NN before finalize)",,,,no,,,,,,
HDFS-7894,Rolling upgrade readiness is not updated in jmx until query command is issued.,Critical,,yes,6) incorrect service result,no,N/A,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,yes,N/A,,N/A,1,N/A,05/Mar/15 22:08,N/A,,3) gray failure,,,yes,2) upgrade + any data,,,,,,,yes,yes,but it's error in webUI,,,,,no,,,,no,,,,,,
HDFS-6130,NPE when upgrading namenode from fsimages older than -32 (interesting),Blocker,,no,2) master down,yes,no,,1.1) data format incompatibility,P,,,no ? (maybe layout version constant?),no,"0.20.2,1.x->2.4.0",,1 major,1,Apr 10 12:31:11 2014,20/Mar/14 7:15,no,,1) clear symptom,,,yes,4) special operation (start name node with -initializeSharedEdits) / 6) special timing ( HA enabled,yes. unit test,,,,,,yes,"no, needs two upgrade",,,,,,no,,,,no,,,,,,
HDFS-4462,2NN will fail to checkpoint after an HDFS upgrade from a pre-federation version of HDFS,Major,checkpoint fails,yes,6) incorrect service result,no,yes,,1.2) data related logic error in full-stop upgrade,P,"the parsing code is there, but it used the wrong parsing code path according to version id",,no,yes,before0.23.0->2.0.2-alpha,,2 major,2,Oct 11 17:36:58 2012,01/Feb/13 1:10,yes,,1) clear symptom,,,no (checkpoint),1) upgrade (rolling upgrade),,,,,,,no (checkpoint),,,,,,,no,,,,no (HA is default),,,,"yes (HA should be tested, checkpoint should happen)",,
CASSANDRA-3166,Rolling upgrades from 0.7 to 0.8 not possible,Normal,old nodes and new nodes cannot communicate,yes,5) rolling upgrade failure,yes,yes,,1.3) data related logic error in a mixed cluster,R,"interesting, complicated case",,yes (protocol version),yes,0.7.9->0.8.2+,,1 minor,2,Jul 26 09:16:18 2011,09/Sep/11 12:45,yes,,3) gray failure,,,yes,"4) special operation (need to do write with QUORUM consistency level. stress testing tool's default consistency level is LOCAL_ONE, but it can be configured to use QUORUM.",yes. unit test,,,,,,yes,yes,,,,,,no,,,,no,yes (full-stop upgrade or restart cluster),,,upgrade_through_versions_test.py,no,1
CASSANDRA-11613,dtest failure in upgrade_tests.cql_tests.TestCQLNodes2RF1_2_2_HEAD_UpTo_Trunk.more_user_types_test,Normal,dtest failure,no,1) whole cluster down,yes,no,,1.1) data format incompatibility,P,,caught in test,no,no,2.x->3.6+,,1 major,2,May 30 17:43 2016,19/Apr/16 21:44,no,,1) clear symptom,,,no,"3) special data format (write, but create user defined type)",yes. UDT used in unit tests,,,,,,no,,,,,,,no,,,,"yes (needs table with implicitly frozen columns, maybe nested)",no (patch and restart),,,yes (upgrade_tests.cql_tests.TestCQLNodes2RF1_2_2_HEAD_UpTo_Trunk.more_user_types_test),yes,1
CASSANDRA-5102,upgrading from 1.1.7 to 1.2.0 caused upgraded nodes to only know about other 1.2.0 nodes,Urgent,"new nodes cannot see old nodes, old nodes cannot communicate with new nodes",yes,5) rolling upgrade failure,yes,yes,,1.3) data related logic error in a mixed cluster,R,,,yes (protocol version),yes,1.1.7->1.2.0,,1 major,2,Dec 29 13:08 2012,03/Jan/13 16:14,yes,,3) gray failure,,,yes,2) upgrade + stress testing,,,,,,,yes,yes,,,,,,no,,,,no,yes (full-stop upgrade),,,,,
CASSANDRA-10360,UnsupportedOperationException when compacting system.size_estimates after 2.1 -> 2.2 -> 3.0 upgrade,Urgent,exception loop for upgrading nodes that need to upgrade range tombstones,not sure whether have to do rolling upgrade,1) whole cluster down,yes,no,,1.1) data format incompatibility,P,,,no,not sure whether have to do rolling upgrade,2.1->3.0,,1 major,1,Nov 6 14:38 2015,16/Sep/15 22:09,no,,1) clear symptom,,,yes (assuming workload gen includes updating size estimates),"4) special operation (compaction, delete)",yes. nodetool has compact command. unit test has delete,,,,,,yes (assuming workload gen includes updating size estimates),yes (assuming workload gen includes updating size estimates),may be,,,,,no,,,,no,no (patch and restart),,,yes (range_tombstones_test + upgrade_through_versions.py),yes,2
CASSANDRA-9554,Avoid digest mismatch storm on upgrade to 3.0,Normal,digest mismatch storm during rolling upgrade,yes,3) performance degradation,no,no,,1.1) data format incompatibility,R,,,no,yes,2.1->3.0,,1 major,2,Nov 6 14:38 2015,05/Jun/15 13:07,no,,3) gray failure,,,yes,2) upgrade + stress testing,,,,,,,yes,yes,,,,,,no,,,,no,yes (full-stop upgrade),,,,,
CASSANDRA-6554,"During upgrade from 1.2 -> 2.0, upgraded node sees other nodes as Down",Normal,upgraded nodes show old nodes as down (but everything still works),yes,6) incorrect service result,no,yes,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,yes,1.2.13->2.0.3+,,1 major,2,Nov 22 08:45 2013,07/Jan/14 3:11,yes,,3) gray failure,,,yes,2) upgrade (rolling upgrade) + stress testing,,,,,,,yes,,,"yes, but run rolling upgrade while stress testing!",,,,no,,,,no,yes (restart),,,,,
CASSANDRA-9582,MarshalException after upgrading to 2.1.6,Normal,upgrade fails for super columns,no,1) whole cluster down,yes,yes,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,no,no,2.0.10->2.1.6,,1 minor,1,Jun 5 10:47 2015,11/Jun/15 15:36,yes,,1) clear symptom,,,yes (assuming supercolumns are tested),3) special data format (super column family),yes,,,,,,yes (assuming supercolumns are tested),"no, needs to run scrub",,,,,,no,,,,no,no (patch and restart),,,,,
CASSANDRA-4576,Error in non-upgraded node's log when upgrading another node to trunk,Normal,upgraded node causes exceptions on old nodes (upgraded node cannot gossip to old node),yes,5) rolling upgrade failure,yes,no,,1.1) data format incompatibility,R,,,no (missing boolean),yes,1.1->1.2,,1 minor,2,Dec 29 13:08 2012,24/Aug/12 18:17,no,,3) gray failure,,,yes,1) upgrade (rolling upgrade),,,,,,,yes,,,yes,,,,no,,,,no,yes (full-stop upgrade),,,,,
CASSANDRA-10122,AssertionError after upgrade to 3.0,Normal,upgraded node throws exception when trying to send message to old node,yes,7) part of cluster down,no,no,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,yes,2.1->3.0,,1 major,2,Nov 6 14:38 2015,18/Aug/15 20:13,no,,1) clear symptom,,,yes,2) upgrade (rolling upgrade) + stress testing (caught in their exsting test),,,,,,,yes,,,yes,,,,no,,,,no,yes (full-stop upgrade),,,,,
CASSANDRA-5814,RowIndexEntry.deletionTime raises UnsupportedOperationException when upgrading to 1.2.7,Normal,upgraded node throws exception when trying to read old sstable format,no,1) whole cluster down (after all upgraded),yes,yes,,1.1) data format incompatibility,P,,,no,no,"1.2.{5,6}->1.2.7",,1 minor,2,Jul 24 17:46 2013,26/Jul/13 21:19,yes,,1) clear symptom,,,yes,"1) upgrade (exception message mentions index row, not sure whether it's refering to the same index as the case below) / 4) special operation (delete operation required)",,,,,,,yes,"not sure, needs to run deleteTime on new version?",,,,,,no,,,,no,no (patch and restart),,,,,
CASSANDRA-11046,Existing indexes are always rebuilt on upgrade to 3.0,Urgent,upgraded node rebuilds index which uses old table name format,no,3) performance degradation,no,yes,,1.1) data format incompatibility,P,,,no,no,x->3.0,,?,1,Nov 6 14:38 2015,20/Jan/16 12:58,yes,,3) gray failure,,,yes,3) special data format (need to define index),yes. unit test,,,,,,yes,yes,,,,,,no,,,,no,no (patch and restart),,,,,
CASSANDRA-11469,dtest failure in upgrade_internal_auth_test.TestAuthUpgrade.upgrade_to_22_test,Normal,upgraded node has a race when reading legacy credentials which could lead to losing the local table,"no, not sure",4) data loss (authentication tables lost before upgrade),yes (if the race happens on every node),yes,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,"no, not sure",2.1->2.2,,1 minor,2,Jul 17 13:46 2015,31/Mar/16 16:21,yes,,1) clear symptom,,,yes,"4) special operation (change user auth privilege) + 6) special timing constraint (concurrency, but it's not uncommon, developers could trigger it 1 out of 3 times)",yes. unit test. timing could be tricky though,,,,,,yes,"no, flacky test",,,,,,yes,,,,no,no (patch and restart),,,,,
CASSANDRA-13294,Possible data loss on upgrade 2.1 - 3.0,Urgent,compacting legacy files could lead to deleting uncompacted files with the same prefix,no,4) data loss,yes,yes,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,no,2.1->3.0,,1 major,1,Nov 6 14:38 2015,03/Mar/17 10:03,yes,,2) data loss,,,yes (assuming compaction is tested),4) special operation (compaction),yes. unit test. but it's not a user level command. we might not be able to translate it directly,,,,,,yes (assuming compaction is tested),"not sure, wether compaction is tested",,,,,,no,,,,no,manual operations to restore data,,,,,
YARN-6654,RollingLevelDBTimelineStore backwards incompatible after fst upgrade,Blocker,"can't read old data, exception, but not sure if exception crashes anyone",no,8) unknown,no (not sure),N/A,,4) broken dependency,P,,,no,no,N/A,,N/A,1,,26/May/17 4:00,N/A,,1) clear symptom,,,yes,1) upgrade,,,,,,,yes,yes,,,,,,no,,,,no,no (4. rollback + abort upgrade),,,,,
HBASE-6054,0.92 failing because of missing commons-io after upgrade to hadoop 1.0.3.,Major,jvm cannot start after upgrade lib,no,1) whole cluster down (after all upgraded),yes,yes,,4) broken dependency,N/A,,,N/A,no,N/A,,N/A,1,Jan 23 16:49:27 2012,18/May/12 21:41,yes,,1) clear symptom,,,yes,1) upgrade,,,,,,,yes,yes,,,,,,no,,,,no,no,,,,,
CASSANDRA-5061,Upgraded cassandra loses all cfs on restart,Normal,data loss,no,6) incorrect service result,no,N/A,,2) data-unrelated bug or logic error in upgrade operation itself,N/A,,,N/A,no,N/A,,N/A,1,N/A,13/Dec/12 14:02,N/A,,3) gray failure,,,yes,2) upgrade + any data on old system,,,,,,,yes,yes,,,,,,no,,,,no,yes,,,,,
CASSANDRA-10822,SSTable data loss when upgrading with row tombstone present,Urgent,data loss,no,4) data loss,no,yes,,1.1) data format incompatibility,P(tombstone),"interesting, developer mentioned it's hard to bisect to get the commit that introduced the bug, They also mentioned that ""Our coverage of upgrade scenario is really bad (as exemplified by this) and we need to fix that ASAP.""",,no,no,"2.1,2.2->3.0",,1 major,1,Jul 30 10:16:24 2015,07/Dec/15 3:32,yes,,2) data loss,,,yes,4) special operation (stress testing does not test delete),yes. unit test,,,,,,yes,,,,no,normal write and delete,no,no,no,,no,no,no (patch and restart),,,,,
